{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[PSMAD]_IDs_Classification_(Final).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marwan-Aj/PMASD/blob/main/IDs_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxBQ4zxAKt0M"
      },
      "source": [
        "## Import ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnAgHi7UWr3R",
        "outputId": "f119da4f-78b8-48f5-9f26-4f425e6dd176"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agcPZPAsyHPf"
      },
      "source": [
        "import glob\n",
        "import re\n",
        "import os\n",
        "from pickle import dump, load\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import librosa\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from keras import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation, ReLU\n",
        "from tensorflow.keras import callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxfQQNaFK_wv"
      },
      "source": [
        "## Some parameters + Load dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z_w3A5lyjAC"
      },
      "source": [
        "PATH = 'drive/MyDrive/PMSAD/'\n",
        "\n",
        "train, test = {}, {}\n",
        "machines = ['ToyCar', 'ToyConveyor', 'fan', 'pump', 'slider', 'valve']\n",
        "for machine in machines : \n",
        "  train[machine] = PATH+machine+'/train/*.wav'\n",
        "  test[machine] = PATH+machine+'/test/*.wav'\n",
        "\n",
        "\n",
        "params = {'fe':16000,\n",
        "          'n_fft': 1024,\n",
        "          'n_mels': 128,\n",
        "          'frames': 5,\n",
        "          'hop_length': 512,\n",
        "          'lower_edge_hertz': 0,\n",
        "          'upper_edge_hertz': 8000}\n",
        "\n",
        "logmel_shape = (320, 128, 1)\n",
        "\n",
        "id_shape=(23)\n",
        "machine_shape=(6)\n",
        "asd_shape=(2)\n",
        "unkPb = 'Problem value must be \\'machine\\' or \\'id\\' or \\'asd\\''\n",
        "\n",
        "\n",
        "## Dict avec les correspondances ids actuels vers ids dans {0...22}\n",
        "ids = {}\n",
        "ids['ToyCar'] = {'04':'03',\n",
        "                 '03':'02',\n",
        "                 '02':'01',\n",
        "                 '01':'00'}\n",
        "ids['ToyConveyor'] = {'03':'06',\n",
        "                      '02':'05',\n",
        "                      '01':'04'}\n",
        "ids['fan'] = {'06':'10',\n",
        "              '04':'09',\n",
        "              '02':'08',\n",
        "              '00':'07'}\n",
        "ids['pump'] = {'06':'14',\n",
        "               '04':'13',\n",
        "               '02':'12',\n",
        "               '00':'11'}\n",
        "ids['slider'] = {'06':'18',\n",
        "                 '04':'17',\n",
        "                 '02':'16',\n",
        "                 '00':'15'}\n",
        "ids['valve'] = {'06':'22',\n",
        "                '04':'21',\n",
        "                '02':'20',\n",
        "                '00':'19'}\n",
        "\n",
        "\n",
        "## Charger un df avec les chemins des fichiers audio et leurs classes\n",
        "## Argument : le chemin vers les données train ou test d'une machine\n",
        "## Colonnes df : filepath(str), machine(str), id(str, entre '00' et '22'), asd(int, 0 ou 1)\n",
        "def load_df(path) :\n",
        "  liste = glob.glob(path)\n",
        "  df = pd.DataFrame(liste, columns=['filepath'])\n",
        "  df['machine'] = df['filepath'].apply(lambda x: re.findall(r\"(ToyCar|ToyConveyor|fan|pump|slider|valve)\", x)[0])\n",
        "  df['id'] = df['filepath'].apply(lambda x: re.findall(r\"[0-9]{2}\", x)[0])\n",
        "  df['id'].replace(ids[df['machine'].unique()[0]], inplace=True)\n",
        "  df['asd'] = df['filepath'].apply(lambda x: str(re.findall(r\"(normal|anomaly)\", x)[0])).replace({'normal':1, 'anomaly':0})\n",
        "  return df\n",
        "\n",
        "\n",
        "## Charger 2 dfs (train et test) avec l'ensemble des chemins des fichiers audio et leurs classes\n",
        "## Colonnes df : filepath(str), machine(str), id(str, entre '00' et '22'), asd(int, 0 ou 1)\n",
        "def load_fulldf() : \n",
        "  machine_dfs = []\n",
        "  for path in train.values() :\n",
        "    machine_dfs.append(load_df(path))\n",
        "  df_train = pd.concat(machine_dfs, ignore_index=True)\n",
        "  machine_dfs = []\n",
        "  for path in test.values() :\n",
        "    machine_dfs.append(load_df(path))\n",
        "  df_test = pd.concat(machine_dfs, ignore_index=True)\n",
        "  return df_train, df_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKo0wernz1PG",
        "outputId": "88ee374f-a2bd-4fda-a7bc-c14ebe0deaa8"
      },
      "source": [
        "df_train, df_test = load_fulldf()\n",
        "print(\"train :\", df_train.shape)\n",
        "print(\"test :\", df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : (20119, 4)\n",
            "test : (10868, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6gfRbagLkNT"
      },
      "source": [
        "## Load train audio & target data functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIp5Z_qBkthW"
      },
      "source": [
        "def load_audio(filepath):\n",
        "    data, fe = librosa.load(filepath, sr=16000)\n",
        "    return data, fe\n",
        "    \n",
        "\n",
        "def logMelSpectrogram(audio, params):\n",
        "\n",
        "    stfts = librosa.stft(audio,\n",
        "                         n_fft = params['n_fft'],\n",
        "                         hop_length = params[\"hop_length\"],\n",
        "                         ).T\n",
        "\n",
        "    power_spectrograms = np.real(stfts * np.conj(stfts))\n",
        "\n",
        "    num_spectrogram_bins = power_spectrograms.shape[-1]\n",
        "\n",
        "    linear_to_mel_weight_matrix = librosa.filters.mel(sr=params['fe'],\n",
        "                                                      n_fft=params['n_fft']+1,\n",
        "                                                      n_mels=params['n_mels'],\n",
        "                                                      fmin=params['lower_edge_hertz'],\n",
        "                                                      fmax=params['upper_edge_hertz']\n",
        "                                                      ).T\n",
        "\n",
        "    mel_spectrograms = np.tensordot(power_spectrograms,\n",
        "                                    linear_to_mel_weight_matrix,\n",
        "                                    1)\n",
        "\n",
        "    return (np.log(mel_spectrograms + 1e-6).astype(np.float32))\n",
        "\n",
        "\n",
        "## Pour charger, dans un narray, les données audio du df en argument\n",
        "def load_data(df, T_max=10.21):\n",
        "  X_audio = []\n",
        "  for i, a_path in enumerate(df.filepath) :\n",
        "    data, fe = load_audio(a_path)\n",
        "    if len(data)>= T_max*fe:\n",
        "      data = data[:int(T_max*fe)]\n",
        "    else :\n",
        "      data = np.concatenate([data, np.zeros(int(T_max*fe - len(data)))])\n",
        "    spectre_audio = logMelSpectrogram(data, params)\n",
        "    X_audio.append(spectre_audio)\n",
        "    if int(i%(df.shape[0]*0.1))==0 : print(i,'on',df.shape[0],'files') \n",
        "  print(\"Done !\")\n",
        "  return np.array(X_audio)\n",
        "\n",
        "\n",
        "## Pour charger les données target train et test, selon la valeur de problem\n",
        "def load_target(df_train, df_test, problem) : \n",
        "  if problem == 'machine' : \n",
        "    ytrain, ytest = df_train.machine, df_test.machine\n",
        "  elif problem == 'id' : \n",
        "    ytrain, ytest = df_train.id, df_test.id\n",
        "  elif problem == 'asd' : \n",
        "    df_train[df_train.machine!=machineRef].asd = 0\n",
        "    df_train[(df_train.machine==machineRef) & (df_train.id!=idRef)].asd = 0\n",
        "    ytrain, ytest = df_train.asd, df_test.asd\n",
        "  else : raise ValueError(unkPb)\n",
        "  return ytrain, ytest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZztjNoSeyiT",
        "outputId": "2a1ed86e-d3a1-4080-e69e-9e297c796954"
      },
      "source": [
        "## On charge l'ensemble des données logmel d'entraînement\n",
        "Xtrain_full = load_data(df_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 on 20119 files\n",
            "2012 on 20119 files\n",
            "4024 on 20119 files\n",
            "6036 on 20119 files\n",
            "8048 on 20119 files\n",
            "10060 on 20119 files\n",
            "12072 on 20119 files\n",
            "14084 on 20119 files\n",
            "16096 on 20119 files\n",
            "18108 on 20119 files\n",
            "Done !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQDltkwQQtSq"
      },
      "source": [
        "## Selon le problème en argument, on charge l'ensemble des données target (train + test)\n",
        "ytrain_full, ytest_full = load_target(df_train, df_test, problem='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy1aRI-yLw9y"
      },
      "source": [
        "## Scale + reshape train & validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtMR5kfh0vt0",
        "outputId": "31bdcc43-5d80-4068-c7c7-539ae90316a0"
      },
      "source": [
        "X = Xtrain_full\n",
        "y = ytrain_full\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "X_train = X_train.reshape([-1, X_train.shape[1] * X_train.shape[2]])\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train = X_train.reshape([-1, X.shape[1], X.shape[2], 1])\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "X_valid = X_valid.reshape([-1, X_valid.shape[1] * X_valid.shape[2]])\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_valid = X_valid.reshape([-1, X.shape[1], X.shape[2], 1])\n",
        "y_valid = to_categorical(y_valid)\n",
        "\n",
        "## On sauvegarde le data scaler\n",
        "dump(scaler, open(PATH+'scaler.pkl', 'wb'))\n",
        "\n",
        "print(X_train.shape, y_train.shape) \n",
        "print(X_valid.shape, y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18107, 320, 128, 1) (18107, 23)\n",
            "(2012, 320, 128, 1) (2012, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV8Xdq2OMKlO"
      },
      "source": [
        "## Model using Conv2D for IDs classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arB6MgiOjEBq"
      },
      "source": [
        "def relu_bn(inputs) :\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "\n",
        "def create_model(yshape, Xshape=logmel_shape):\n",
        "\n",
        "  inputs = Input(shape=Xshape)\n",
        "\n",
        "  x = Conv2D(32, (5, 5), strides=(2,1), padding='same')(inputs)\n",
        "  x = relu_bn(x)\n",
        "  x = Conv2D(64, (5, 5), strides=(2,1), padding='same')(x)\n",
        "  x = relu_bn(x)\n",
        "  x = Conv2D(128, (3, 3), strides=(1,1), padding='same')(x)\n",
        "  x = MaxPooling2D(pool_size=2)(x)\n",
        "  x = Conv2D(256, (3, 3), strides=(1,1), padding='same')(x)\n",
        "  x = relu_bn(x)\n",
        "  x = MaxPooling2D(pool_size=2)(x)\n",
        "  x = Conv2D(512, (3, 3), strides=(1,1), padding='same')(x)\n",
        "  x = relu_bn(x)\n",
        "  x = MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(units = 512)(x)\n",
        "  x = relu_bn(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(units = 512)(x)\n",
        "  x = relu_bn(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(units = 1024)(x)\n",
        "  x = relu_bn(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(units = 1024)(x)\n",
        "  x = relu_bn(x)\n",
        "\n",
        "  outputs = Dense(units=yshape, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "lr_plateau = callbacks.ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                                         patience = 10,\n",
        "                                         factor = 0.5,\n",
        "                                         verbose = 0,\n",
        "                                         mode = 'min')\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath = PATH+'checkpoint',\n",
        "                                       save_weights_only = True,\n",
        "                                       monitor = 'val_acc',\n",
        "                                       mode = 'max',\n",
        "                                       save_best_only = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ss_MrioZfrA",
        "outputId": "58818428-b00a-4547-a038-059bb408d3d2"
      },
      "source": [
        "model = create_model(yshape=id_shape)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 320, 128, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 160, 128, 32)      832       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 160, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 160, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 80, 128, 64)       51264     \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 80, 128, 64)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 80, 128, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 80, 128, 128)      73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 40, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 40, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 40, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 40, 64, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 20, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 20, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 20, 32, 512)       2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 10, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 81920)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               41943552  \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 23)                23575     \n",
            "=================================================================\n",
            "Total params: 45,421,719\n",
            "Trainable params: 45,413,847\n",
            "Non-trainable params: 7,872\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x8rqtt9mU5tT",
        "outputId": "e9b431ee-c858-4b66-9e20-a732d059157d"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=256, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks = [lr_plateau, checkpoint],\n",
        "                    verbose=1)\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "71/71 [==============================] - 92s 1s/step - loss: 1.6579 - acc: 0.5033 - val_loss: 8.8102 - val_acc: 0.0527\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.1617 - acc: 0.9435 - val_loss: 13.2534 - val_acc: 0.0527\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0768 - acc: 0.9751 - val_loss: 17.0270 - val_acc: 0.0472\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0448 - acc: 0.9846 - val_loss: 38.3964 - val_acc: 0.0472\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0240 - acc: 0.9919 - val_loss: 65.9712 - val_acc: 0.0586\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0193 - acc: 0.9941 - val_loss: 36.1804 - val_acc: 0.0492\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0169 - acc: 0.9940 - val_loss: 15.2714 - val_acc: 0.1262\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0249 - acc: 0.9922 - val_loss: 10.7646 - val_acc: 0.1466\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0317 - acc: 0.9893 - val_loss: 0.5597 - val_acc: 0.8802\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0199 - acc: 0.9928 - val_loss: 0.4696 - val_acc: 0.8772\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.2410 - val_acc: 0.9563\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0070 - acc: 0.9974 - val_loss: 0.0549 - val_acc: 0.9841\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.8556 - val_acc: 0.8782\n",
            "Epoch 14/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.3141 - val_acc: 0.9140\n",
            "Epoch 15/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0199 - acc: 0.9945 - val_loss: 0.2250 - val_acc: 0.9404\n",
            "Epoch 16/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.1337 - val_acc: 0.9687\n",
            "Epoch 17/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0136 - acc: 0.9962 - val_loss: 1.2618 - val_acc: 0.7425\n",
            "Epoch 18/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0120 - acc: 0.9964 - val_loss: 2.0627 - val_acc: 0.6769\n",
            "Epoch 19/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0399 - val_acc: 0.9856\n",
            "Epoch 20/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.2624 - val_acc: 0.9433\n",
            "Epoch 21/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0059 - acc: 0.9984 - val_loss: 1.6129 - val_acc: 0.6705\n",
            "Epoch 22/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.1221 - val_acc: 0.9692\n",
            "Epoch 23/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.2536 - val_acc: 0.9428\n",
            "Epoch 24/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0108 - acc: 0.9969 - val_loss: 0.6748 - val_acc: 0.8757\n",
            "Epoch 25/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0110 - acc: 0.9960 - val_loss: 0.1016 - val_acc: 0.9727\n",
            "Epoch 26/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0110 - acc: 0.9968 - val_loss: 2.2620 - val_acc: 0.6909\n",
            "Epoch 27/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.1236 - val_acc: 0.9737\n",
            "Epoch 28/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0509 - val_acc: 0.9871\n",
            "Epoch 29/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.4515e-04 - acc: 0.9999 - val_loss: 0.0463 - val_acc: 0.9881\n",
            "Epoch 30/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 0.0025 - acc: 0.9997 - val_loss: 0.0122 - val_acc: 0.9960\n",
            "Epoch 31/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.0156e-04 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9975\n",
            "Epoch 32/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.9446e-05 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9980\n",
            "Epoch 33/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 6.9808e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9975\n",
            "Epoch 34/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 5.2982e-05 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 0.9975\n",
            "Epoch 35/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.9363e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9950\n",
            "Epoch 36/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 4.8444e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9970\n",
            "Epoch 37/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 3.8786e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9980\n",
            "Epoch 38/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 3.8745e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9975\n",
            "Epoch 39/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 5.3632e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9975\n",
            "Epoch 40/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.9467e-05 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9975\n",
            "Epoch 41/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 3.3256e-05 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9975\n",
            "Epoch 42/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.6262e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 43/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 4.8353e-05 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9980\n",
            "Epoch 44/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 3.3078e-05 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9975\n",
            "Epoch 45/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.2183e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9970\n",
            "Epoch 46/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.9113e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 47/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.0566e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9975\n",
            "Epoch 48/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.4776e-05 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9975\n",
            "Epoch 49/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.7613e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9970\n",
            "Epoch 50/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.8708e-05 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9970\n",
            "Epoch 51/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.3652e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9975\n",
            "Epoch 52/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.8843e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9975\n",
            "Epoch 53/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.7558e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9975\n",
            "Epoch 54/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.4563e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9975\n",
            "Epoch 55/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.2057e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9975\n",
            "Epoch 56/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.6256e-05 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9975\n",
            "Epoch 57/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.7068e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9975\n",
            "Epoch 58/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.2571e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9975\n",
            "Epoch 59/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.3682e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9975\n",
            "Epoch 60/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.7616e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9975\n",
            "Epoch 61/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.8203e-06 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9975\n",
            "Epoch 62/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.4671e-06 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9980\n",
            "Epoch 63/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.5689e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9980\n",
            "Epoch 64/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.3173e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9975\n",
            "Epoch 65/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 8.9238e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9975\n",
            "Epoch 66/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.2965e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9975\n",
            "Epoch 67/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.1349e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 68/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 2.3831e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9975\n",
            "Epoch 69/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 6.8986e-06 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9975\n",
            "Epoch 70/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.1037e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9975\n",
            "Epoch 71/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.0499e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9975\n",
            "Epoch 72/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.2058e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 73/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.4495e-06 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9975\n",
            "Epoch 74/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.1291e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 75/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.1784e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 76/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.6424e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9975\n",
            "Epoch 77/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.5817e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9975\n",
            "Epoch 78/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.6300e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9975\n",
            "Epoch 79/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.1175e-06 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9975\n",
            "Epoch 80/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 6.7407e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 81/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.0083e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 82/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.3052e-05 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
            "Epoch 83/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.0413e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 84/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 8.4933e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 85/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.0230e-05 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9975\n",
            "Epoch 86/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.0395e-05 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9980\n",
            "Epoch 87/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 6.4513e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9980\n",
            "Epoch 88/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.6810e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 89/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 8.4236e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9975\n",
            "Epoch 90/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.7136e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 91/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.5178e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 92/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 8.7271e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 93/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 8.9695e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 94/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.1102e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9980\n",
            "Epoch 95/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.2603e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9980\n",
            "Epoch 96/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.1751e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9980\n",
            "Epoch 97/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.3514e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9980\n",
            "Epoch 98/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 7.3775e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9980\n",
            "Epoch 99/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 9.5210e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9975\n",
            "Epoch 100/100\n",
            "71/71 [==============================] - 73s 1s/step - loss: 1.6448e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}